FFdf$Contact_Weekday <- wday(FFdf$Last_Contact, label = TRUE)
FFdf$Contact_Hour <- hour(FFdf$Last_Contact)
# View the extracted date components
cat("\nExtracted Date Components (sample):\n")
head(FFdf[, c("Last_Contact", "Contact_Year", "Contact_Month", "Contact_Day", "Contact_Weekday", "Contact_Hour")], 10)
# Summary of date components
cat("\nContact Year Distribution:\n")
table(FFdf$Contact_Year, useNA = "ifany")
cat("\nContact Month Distribution:\n")
table(FFdf$Contact_Month, useNA = "ifany")
cat("\nContact Weekday Distribution:\n")
table(FFdf$Contact_Weekday, useNA = "ifany")
cat("\nContact Hour Summary:\n")
summary(FFdf$Contact_Hour)
head(FFdf$Last_Contact, 10)
FFdf$Last_Contact <- ymd_hms(as.character(FFdf$Last_Contact))
cat("Last_Contact sample values:\n")
head(FFdf$Last_Contact, 10)
cat("\nLast_Contact class:", class(FFdf$Last_Contact), "\n")
FFdf$Last_Contact <- ymd_hms(as.character(FFdf$Last_Contact))
cat("\nAfter conversion, Last_Contact class:", class(FFdf$Last_Contact), "\n")
FFdf$Contact_Year <- year(FFdf$Last_Contact)
FFdf$Contact_Month <- month(FFdf$Last_Contact)
FFdf$Contact_Day <- day(FFdf$Last_Contact)
FFdf$Contact_Weekday <- wday(FFdf$Last_Contact, label = TRUE)
FFdf$Contact_Hour <- hour(FFdf$Last_Contact)
# Setup Chunk - Load Required Libraries
# Multivariate Imputation by Chained Equations
library(mice)
# Visualizing Missing Values
library(VIM)
# Data manipulation and tidy data
library(tidyverse)
# Data visualization
library(ggplot2)
# Reshaping data
library(reshape2)
# Correlation visualization
library(corrplot)
# Date handling
library(lubridate)
# Pretty tables
library(flextable)
# Set working directory
setwd("C:/Users/david/Desktop/Spring-Semester-/Missing Data")
# Load the raw data files
MainDF <- read.csv("Raw.csv")
StoreDF <- read.csv("StoreTable.csv")
ConcessDF <- read.csv("ConcessTable.csv")
CustomerDF <- read.csv("CustomerTable.csv")
# Check dimensions of each file
cat("MainDF dimensions:", dim(MainDF), "\n")
cat("StoreDF dimensions:", dim(StoreDF), "\n")
cat("ConcessDF dimensions:", dim(ConcessDF), "\n")
cat("CustomerDF dimensions:", dim(CustomerDF), "\n")
# Check for missing values in each file
cat("\nMissing values per column in MainDF:\n")
colSums(is.na(MainDF))
# Create the flat file by merging all tables
# Start with MainDF as the base
FFdf <- MainDF
cat("Starting rows:", nrow(FFdf), "\n")
# Merge with StoreDF (left join on Cust_ID)
FFdf <- merge(FFdf, StoreDF, by = "Cust_ID", all.x = TRUE)
cat("After StoreDF merge:", nrow(FFdf), "\n")
# Merge with ConcessDF
FFdf <- merge(FFdf, ConcessDF, by = "Cust_ID", all.x = TRUE)
cat("After ConcessDF merge:", nrow(FFdf), "\n")
# Merge with CustomerDF
FFdf <- merge(FFdf, CustomerDF, by = "Cust_ID", all.x = TRUE)
cat("After CustomerDF merge:", nrow(FFdf), "\n")
# Store dimensions for reporting
a <- dim(FFdf)
cat("\nFinal flat file dimensions - Rows:", a[1], "Columns:", a[2], "\n")
# Create an identifier variable
FFdf$ID <- 1:nrow(FFdf)
# Reorder columns: Y-variable first, then alphabetically
y_var <- "Y01"
other_vars <- sort(setdiff(names(FFdf), y_var))
FFdf <- FFdf[, c(y_var, other_vars)]
# View the structure of the dataset
cat("Structure of the flat file:\n")
str(FFdf)
# Summary statistics for all variables
cat("\nSummary Statistics:\n")
summary(FFdf)
# Check variable classes
cat("\nVariable Classes:\n")
sapply(FFdf, class)
# Histograms for a few numeric variables to understand distributions
par(mfrow = c(2, 2))
hist(FFdf$Age, main = "Distribution of Age", xlab = "Age", col = "steelblue", breaks = 20)
hist(FFdf$tenure, main = "Distribution of Tenure", xlab = "Tenure (Years)", col = "steelblue", breaks = 20)
hist(FFdf$NumSeats, main = "Distribution of NumSeats", xlab = "Number of Seats", col = "steelblue")
hist(FFdf$Total.Spent, main = "Distribution of Total Spent", xlab = "Total Spent ($)", col = "steelblue", breaks = 30)
par(mfrow = c(1, 1))
# Response variable distribution
cat("\n=== RESPONSE VARIABLE (Y01) ===\n")
table(FFdf$Y01)
barplot(table(FFdf$Y01), main = "Distribution of Y01 (Response Variable)",
col = c("coral", "steelblue"), names.arg = c("0 (No)", "1 (Yes)"))
# View all variable names
cat("Current Variable Names:\n")
names(FFdf)
# Check dimensions
cat("\nDataset has", nrow(FFdf), "rows and", ncol(FFdf), "columns\n")
# Clean up variable names - replace dots and spaces with underscores
names(FFdf) <- gsub("\\.", "_", names(FFdf))
names(FFdf) <- gsub(" ", "_", names(FFdf))
# Capitalize first letter of each word segment
names(FFdf) <- gsub("(^|_)([a-z])", "\\1\\U\\2", names(FFdf), perl = TRUE)
cat("\nCleaned Variable Names:\n")
names(FFdf)
# Check for unique identifiers
cat("\nUnique Cust_ID count:", length(unique(FFdf$Cust_ID)), "\n")
cat("Total rows:", nrow(FFdf), "\n")
# Check current variable types
cat("Variable Types Before Conversion:\n")
sapply(FFdf, class)
# Identify character variables
chr_vars <- names(FFdf)[sapply(FFdf, is.character)]
cat("\nCharacter Variables to Convert:\n")
print(chr_vars)
# Convert character variables to factors
for(var in chr_vars) {
FFdf[[var]] <- as.factor(FFdf[[var]])
}
# Check variable types after conversion
cat("\nVariable Types After Conversion:\n")
sapply(FFdf, class)
# Check levels of factor variables
cat("\nLevels for Key Factor Variables:\n")
cat("\nSex levels:\n")
levels(FFdf$Sex)
cat("\nMarital status levels:\n")
levels(FFdf$Marital)
cat("\nEducational_Level levels:\n")
levels(FFdf$Educational_Level)
cat("\nAccount_Type levels:\n")
levels(FFdf$Account_Type)
# Use glimpse for a compact view
cat("\nGlimpse of Dataset:\n")
glimpse(FFdf)
# Check frequency tables for categorical variables
cat("Sex Distribution:\n")
table(FFdf$Sex, useNA = "ifany")
cat("\nMarital Status Distribution:\n")
table(FFdf$Marital, useNA = "ifany")
# NOTE: "U" likely means "Unknown" - may want to treat as NA or keep separate
cat("\nEducational Level Distribution:\n")
table(FFdf$Educational_Level, useNA = "ifany")
cat("\nJob Sector Distribution:\n")
table(FFdf$Job_Sector, useNA = "ifany")
cat("\nState Name Distribution:\n")
table(FFdf$State_Name, useNA = "ifany")
cat("\nFavorite Team Distribution:\n")
table(FFdf$Favorite_Team, useNA = "ifany")
cat("\nFavorite Sport Distribution:\n")
table(FFdf$Favorite_Sport, useNA = "ifany")
cat("\nMode of Transport Distribution:\n")
table(FFdf$Mode_Of_Transport, useNA = "ifany")
cat("\nAccount Type Distribution:\n")
table(FFdf$Account_Type, useNA = "ifany")
cat("\nSeating Location Distribution:\n")
table(FFdf$Seating_Location, useNA = "ifany")
# Check for unusual values in numeric variables
cat("Age range:", range(FFdf$Age, na.rm = TRUE), "\n")
# NOTE: Max age of 99 seems high - potential data entry error or placeholder
cat("Tenure range:", range(FFdf$Tenure, na.rm = TRUE), "\n")
cat("NumSeats range:", range(FFdf$NumSeats, na.rm = TRUE), "\n")
cat("Num_Children range:", range(FFdf$Num_Children, na.rm = TRUE), "\n")
# Check for potential bogus values (999 often means missing)
cat("DistA values equal to 999:", sum(FFdf$DistA == 999, na.rm = TRUE), "\n")
# Convert 999 to NA in DistA (these are placeholder missing values)
FFdf$DistA[FFdf$DistA == 999] <- NA
cat("After conversion, DistA NA count:", sum(is.na(FFdf$DistA)), "\n")
# Check Arrival_Time (negative values = minutes before game start)
cat("Arrival_Time values:\n")
table(FFdf$Arrival_Time, useNA = "ifany")
# NOTE: Negative values like -30, -15 likely mean "30 min before", "15 min before"
# Check Survey_Comp for outliers (should be 0-1 range typically)
cat("Survey_Comp range:", range(FFdf$Survey_Comp, na.rm = TRUE), "\n")
cat("Survey_Comp values > 1:\n")
print(FFdf$Survey_Comp[FFdf$Survey_Comp > 1])
hist(FFdf$Survey_Comp)
# Check for redundant columns (State_Name vs State_Loc after merge)
cat("State_Name unique values:", length(unique(FFdf$State_Name)), "\n")
cat("State_Loc unique values:", length(unique(FFdf$State_Loc)), "\n")
# Check if they represent the same information
cat("\nCross-tabulation of State_Name vs State_Loc (sample):\n")
head(table(FFdf$State_Name, FFdf$State_Loc), 10)
# Check for potential identifier variables that shouldn't be used in modeling
cat("Cust_ID unique count:", length(unique(FFdf$Cust_ID)), "out of", nrow(FFdf), "rows\n")
cat("ID unique count:", length(unique(FFdf$ID)), "out of", nrow(FFdf), "rows\n")
#Use ID over Cust
cat("Last_Contact sample values:\n")
head(FFdf$Last_Contact, 10)
cat("\nLast_Contact class:", class(FFdf$Last_Contact), "\n")
FFdf$Last_Contact <- ymd_hms(as.character(FFdf$Last_Contact))
cat("\nAfter conversion, Last_Contact class:", class(FFdf$Last_Contact), "\n")
FFdf$Contact_Year <- year(FFdf$Last_Contact)
FFdf$Contact_Month <- month(FFdf$Last_Contact)
FFdf$Contact_Day <- day(FFdf$Last_Contact)
FFdf$Contact_Weekday <- wday(FFdf$Last_Contact, label = TRUE)
FFdf$Contact_Hour <- hour(FFdf$Last_Contact)
at("\nExtracted Date Components (sample):\n")
cat("\nExtracted Date Components (sample):\n")
head(FFdf[, c("Last_Contact", "Contact_Year", "Contact_Month", "Contact_Day", "Contact_Weekday", "Contact_Hour")], 10)
cat("\nContact Year Distribution:\n")
table(FFdf$Contact_Year, useNA = "ifany")
cat("\nContact Month Distribution:\n")
table(FFdf$Contact_Month, useNA = "ifany")
cat("\nContact Weekday Distribution:\n")
table(FFdf$Contact_Weekday, useNA = "ifany")
cat("\nContact Month Distribution:\n")
table(FFdf$Contact_Month, useNA = "ifany")
cat("\nContact Hour Summary:\n")
summary(FFdf$Contact_Hour)
# Final dataset summary
cat("========================================\n")
cat("       FINAL DATASET SUMMARY           \n")
cat("========================================\n\n")
cat("Total Rows:", nrow(FFdf), "\n")
cat("Total Columns:", ncol(FFdf), "\n")
cat("\nTotal Missing Values:", sum(is.na(FFdf)), "\n")
# Missing values by column (only show columns with missing)
cat("\n=== MISSING VALUES PER COLUMN ===\n")
na_counts <- colSums(is.na(FFdf))
na_counts_sorted <- sort(na_counts[na_counts > 0], decreasing = TRUE)
print(na_counts_sorted)
# Variable types summary
cat("\n=== VARIABLE TYPES SUMMARY ===\n")
print(table(sapply(FFdf, class)))
# Visualize missing data pattern
cat("\n=== MISSING DATA VISUALIZATION ===\n")
aggr(FFdf, col = c('steelblue', 'red'), numbers = TRUE, sortVars = TRUE,
labels = names(FFdf), cex.axis = 0.5, gap = 2,
ylab = c("Missing Data Pattern", "Pattern"))
cat("Total Rows:", nrow(FFdf), "\n")
cat("Total Columns:", ncol(FFdf), "\n")
cat("\nTotal Missing Values:", sum(is.na(FFdf)), "\n")
# Missing values by column (only show columns with missing)
cat("\n=== MISSING VALUES PER COLUMN ===\n")
na_counts <- colSums(is.na(FFdf))
na_counts_sorted <- sort(na_counts[na_counts > 0], decreasing = TRUE)
print(na_counts_sorted)
# Check the Last_Contact column from CustomerDF
cat("Last_Contact sample values:\n")
head(FFdf$Last_Contact, 10)
cat("\nLast_Contact class:", class(FFdf$Last_Contact), "\n")
# Convert Last_Contact to datetime format
FFdf$Last_Contact <- ymd_hms(as.character(FFdf$Last_Contact))
cat("\nAfter conversion, Last_Contact class:", class(FFdf$Last_Contact), "\n")
# Extract date components
FFdf$Contact_Year <- year(FFdf$Last_Contact)
FFdf$Contact_Month <- month(FFdf$Last_Contact)
FFdf$Contact_Day <- day(FFdf$Last_Contact)
FFdf$Contact_Weekday <- wday(FFdf$Last_Contact, label = TRUE)
FFdf$Contact_Hour <- hour(FFdf$Last_Contact)
# View the extracted date components
cat("\nExtracted Date Components (sample):\n")
head(FFdf[, c("Last_Contact", "Contact_Year", "Contact_Month", "Contact_Day", "Contact_Weekday", "Contact_Hour")], 10)
# Summary of date components
cat("\nContact Year Distribution:\n")
table(FFdf$Contact_Year, useNA = "ifany")
cat("\nContact Month Distribution:\n")
table(FFdf$Contact_Month, useNA = "ifany")
cat("\nContact Weekday Distribution:\n")
table(FFdf$Contact_Weekday, useNA = "ifany")
cat("\nContact Hour Summary:\n")
summary(FFdf$Contact_Hour)
# Setup Chunk - Load Required Libraries
library(mice)
library(VIM)
library(tidyverse)
library(ggplot2)
library(reshape2)
library(corrplot)
library(lubridate)
library(flextable)
setwd("C:/Users/david/Desktop/Spring-Semester-/Missing Data")
# Load the raw data files
MainDF <- read.csv("Raw.csv")
StoreDF <- read.csv("StoreTable.csv")
ConcessDF <- read.csv("ConcessTable.csv")
CustomerDF <- read.csv("CustomerTable.csv")
# Check dimensions of each file
cat("MainDF:", dim(MainDF), "| StoreDF:", dim(StoreDF),
"| ConcessDF:", dim(ConcessDF), "| CustomerDF:", dim(CustomerDF), "\n")
# Create flat file by merging all tables on Cust_ID
FFdf <- MainDF
FFdf <- merge(FFdf, StoreDF, by = "Cust_ID", all.x = TRUE)
FFdf <- merge(FFdf, ConcessDF, by = "Cust_ID", all.x = TRUE)
FFdf <- merge(FFdf, CustomerDF, by = "Cust_ID", all.x = TRUE)
cat("Final flat file dimensions - Rows:", nrow(FFdf), "Columns:", ncol(FFdf), "\n")
# Create an identifier variable
FFdf$ID <- 1:nrow(FFdf)
# Reorder columns: Y-variable first, then alphabetically
y_var <- "Y01"
other_vars <- sort(setdiff(names(FFdf), y_var))
FFdf <- FFdf[, c(y_var, other_vars)]
# Histograms for key numeric variables
par(mfrow = c(2, 2))
hist(FFdf$Age, main = "Distribution of Age", xlab = "Age", col = "steelblue", breaks = 20)
hist(FFdf$tenure, main = "Distribution of Tenure", xlab = "Tenure (Years)", col = "steelblue", breaks = 20)
hist(FFdf$NumSeats, main = "Distribution of NumSeats", xlab = "Number of Seats", col = "steelblue")
hist(FFdf$Total.Spent, main = "Distribution of Total Spent", xlab = "Total Spent ($)", col = "steelblue", breaks = 30)
par(mfrow = c(1, 1))
# Response variable distribution
cat("Response Variable (Y01):", table(FFdf$Y01), "\n")
barplot(table(FFdf$Y01), main = "Distribution of Y01 (Response Variable)",
col = c("coral", "steelblue"), names.arg = c("0 (No)", "1 (Yes)"))
# Clean up variable names - replace dots/spaces with underscores, capitalize
names(FFdf) <- gsub("\\.", "_", names(FFdf))
names(FFdf) <- gsub(" ", "_", names(FFdf))
names(FFdf) <- gsub("(^|_)([a-z])", "\\1\\U\\2", names(FFdf), perl = TRUE)
cat("Dataset:", nrow(FFdf), "rows,", ncol(FFdf), "columns\n")
cat("Unique Cust_ID:", length(unique(FFdf$Cust_ID)), "out of", nrow(FFdf), "rows\n")
# Setup Chunk - Load Required Libraries
library(mice)
library(VIM)
library(tidyverse)
library(ggplot2)
library(reshape2)
library(corrplot)
library(lubridate)
library(flextable)
setwd("C:/Users/david/Desktop/Spring-Semester-/Missing Data")
# Load the raw data files
MainDF <- read.csv("Raw.csv")
StoreDF <- read.csv("StoreTable.csv")
ConcessDF <- read.csv("ConcessTable.csv")
CustomerDF <- read.csv("CustomerTable.csv")
# Check dimensions of each file
cat("MainDF:", dim(MainDF), "| StoreDF:", dim(StoreDF),
"| ConcessDF:", dim(ConcessDF), "| CustomerDF:", dim(CustomerDF), "\n")
# Check for duplicate Cust_IDs in each source table BEFORE merging
cat("Duplicates in MainDF:", sum(duplicated(MainDF$Cust_ID)), "\n")
cat("Duplicates in StoreDF:", sum(duplicated(StoreDF$Cust_ID)), "\n")
cat("Duplicates in ConcessDF:", sum(duplicated(ConcessDF$Cust_ID)), "\n")
cat("Duplicates in CustomerDF:", sum(duplicated(CustomerDF$Cust_ID)), "\n")
# Create flat file by merging all tables on Cust_ID
FFdf <- MainDF
FFdf <- merge(FFdf, StoreDF, by = "Cust_ID", all.x = TRUE)
FFdf <- merge(FFdf, ConcessDF, by = "Cust_ID", all.x = TRUE)
FFdf <- merge(FFdf, CustomerDF, by = "Cust_ID", all.x = TRUE)
cat("Final flat file dimensions - Rows:", nrow(FFdf), "Columns:", ncol(FFdf), "\n")
cat("Unique Cust_ID:", length(unique(FFdf$Cust_ID)), "| Duplicate rows:", nrow(FFdf) - length(unique(FFdf$Cust_ID)), "\n")
# Create an identifier variable
FFdf$ID <- 1:nrow(FFdf)
# Reorder columns: Y-variable first, then alphabetically
y_var <- "Y01"
other_vars <- sort(setdiff(names(FFdf), y_var))
FFdf <- FFdf[, c(y_var, other_vars)]
# Histograms for key numeric variables
par(mfrow = c(2, 2))
hist(FFdf$Age, main = "Distribution of Age", xlab = "Age", col = "steelblue", breaks = 20)
hist(FFdf$tenure, main = "Distribution of Tenure", xlab = "Tenure (Years)", col = "steelblue", breaks = 20)
hist(FFdf$NumSeats, main = "Distribution of NumSeats", xlab = "Number of Seats", col = "steelblue")
hist(FFdf$Total.Spent, main = "Distribution of Total Spent", xlab = "Total Spent ($)", col = "steelblue", breaks = 30)
par(mfrow = c(1, 1))
# Response variable distribution
cat("Response Variable (Y01):", table(FFdf$Y01), "\n")
barplot(table(FFdf$Y01), main = "Distribution of Y01 (Response Variable)",
col = c("coral", "steelblue"), names.arg = c("0 (No)", "1 (Yes)"))
# Clean up variable names - replace dots/spaces with underscores, capitalize
names(FFdf) <- gsub("\\.", "_", names(FFdf))
names(FFdf) <- gsub(" ", "_", names(FFdf))
names(FFdf) <- gsub("(^|_)([a-z])", "\\1\\U\\2", names(FFdf), perl = TRUE)
cat("Dataset:", nrow(FFdf), "rows,", ncol(FFdf), "columns\n")
cat("Unique Cust_ID:", length(unique(FFdf$Cust_ID)), "out of", nrow(FFdf), "rows\n")
# Identify character variables
chr_vars <- names(FFdf)[sapply(FFdf, is.character)]
cat("Character variables to convert:", length(chr_vars), "\n")
# Convert character variables to factors
for(var in chr_vars) {
FFdf[[var]] <- as.factor(FFdf[[var]])
}
# Show key factor levels
cat("\nSex levels:", levels(FFdf$Sex), "\n")
cat("Marital levels:", levels(FFdf$Marital), "\n")
cat("Account_Type levels:", levels(FFdf$Account_Type), "\n")
# Check numeric variable ranges
cat("Age range:", range(FFdf$Age, na.rm = TRUE), "\n")
cat("Tenure range:", range(FFdf$Tenure, na.rm = TRUE), "\n")
cat("NumSeats range:", range(FFdf$NumSeats, na.rm = TRUE), "\n")
# Check for 999 placeholder values in DistA
cat("\nDistA values = 999:", sum(FFdf$DistA == 999, na.rm = TRUE), "\n")
# Convert 999 to NA (placeholder for missing)
FFdf$DistA[FFdf$DistA == 999] <- NA
cat("DistA NA count after conversion:", sum(is.na(FFdf$DistA)), "\n")
# Check Survey_Comp for outliers (expected range 0-1)
cat("\nSurvey_Comp range:", range(FFdf$Survey_Comp, na.rm = TRUE), "\n")
cat("Survey_Comp values > 1:", sum(FFdf$Survey_Comp > 1, na.rm = TRUE), "\n")
# Check for redundant columns
cat("\nState_Name unique:", length(unique(FFdf$State_Name)),
"| State_Loc unique:", length(unique(FFdf$State_Loc)), "\n")
# Convert Last_Contact to datetime format
FFdf$Last_Contact <- ymd_hms(as.character(FFdf$Last_Contact))
# Extract date components
FFdf$Contact_Year <- year(FFdf$Last_Contact)
FFdf$Contact_Month <- month(FFdf$Last_Contact)
FFdf$Contact_Day <- day(FFdf$Last_Contact)
FFdf$Contact_Weekday <- wday(FFdf$Last_Contact, label = TRUE)
FFdf$Contact_Hour <- hour(FFdf$Last_Contact)
cat("Date components extracted: Contact_Year, Contact_Month, Contact_Day, Contact_Weekday, Contact_Hour\n")
cat("Contact Year range:", range(FFdf$Contact_Year, na.rm = TRUE), "\n")
cat("Contact Hour range:", range(FFdf$Contact_Hour, na.rm = TRUE), "\n")
cat("Final Dataset:", nrow(FFdf), "rows x", ncol(FFdf), "columns\n")
cat("Total Missing Values:", sum(is.na(FFdf)), "\n")
# Show columns with missing values
na_counts <- colSums(is.na(FFdf))
na_cols <- na_counts[na_counts > 0]
cat("\nColumns with missing values:\n")
print(sort(na_cols, decreasing = TRUE))
# Setup Chunk - Load Required Libraries
library(mice)
library(VIM)
library(tidyverse)
library(ggplot2)
library(reshape2)
library(corrplot)
library(lubridate)
library(flextable)
setwd("C:/Users/david/Desktop/Spring-Semester-/Missing Data")
# Load the raw data files
MainDF <- read.csv("Raw.csv")
StoreDF <- read.csv("StoreTable.csv")
ConcessDF <- read.csv("ConcessTable.csv")
CustomerDF <- read.csv("CustomerTable.csv")
# Check dimensions of each file
cat("MainDF:", dim(MainDF), "| StoreDF:", dim(StoreDF),
"| ConcessDF:", dim(ConcessDF), "| CustomerDF:", dim(CustomerDF), "\n")
# Check for duplicate Cust_IDs in each source table BEFORE merging
cat("Duplicates in MainDF:", sum(duplicated(MainDF$Cust_ID)), "\n")
cat("Duplicates in StoreDF:", sum(duplicated(StoreDF$Cust_ID)), "\n")
cat("Duplicates in ConcessDF:", sum(duplicated(ConcessDF$Cust_ID)), "\n")
cat("Duplicates in CustomerDF:", sum(duplicated(CustomerDF$Cust_ID)), "\n")
# Create flat file by merging all tables on Cust_ID
FFdf <- MainDF
FFdf <- merge(FFdf, StoreDF, by = "Cust_ID", all.x = TRUE)
FFdf <- merge(FFdf, ConcessDF, by = "Cust_ID", all.x = TRUE)
FFdf <- merge(FFdf, CustomerDF, by = "Cust_ID", all.x = TRUE)
cat("Final flat file dimensions - Rows:", nrow(FFdf), "Columns:", ncol(FFdf), "\n")
cat("Unique Cust_ID:", length(unique(FFdf$Cust_ID)), "| Duplicate rows:", nrow(FFdf) - length(unique(FFdf$Cust_ID)), "\n")
# Create an identifier variable
FFdf$ID <- 1:nrow(FFdf)
# Reorder columns: Y-variable first, then alphabetically
y_var <- "Y01"
other_vars <- sort(setdiff(names(FFdf), y_var))
FFdf <- FFdf[, c(y_var, other_vars)]
# Histograms for key numeric variables
par(mfrow = c(2, 2))
hist(FFdf$Age, main = "Distribution of Age", xlab = "Age", col = "steelblue", breaks = 20)
hist(FFdf$tenure, main = "Distribution of Tenure", xlab = "Tenure (Years)", col = "steelblue", breaks = 20)
hist(FFdf$NumSeats, main = "Distribution of NumSeats", xlab = "Number of Seats", col = "steelblue")
hist(FFdf$Total.Spent, main = "Distribution of Total Spent", xlab = "Total Spent ($)", col = "steelblue", breaks = 30)
par(mfrow = c(1, 1))
# Response variable distribution
cat("Response Variable (Y01):", table(FFdf$Y01), "\n")
barplot(table(FFdf$Y01), main = "Distribution of Y01 (Response Variable)",
col = c("coral", "steelblue"), names.arg = c("0 (No)", "1 (Yes)"))
# Clean up variable names - replace dots/spaces with underscores, capitalize
names(FFdf) <- gsub("\\.", "_", names(FFdf))
names(FFdf) <- gsub(" ", "_", names(FFdf))
names(FFdf) <- gsub("(^|_)([a-z])", "\\1\\U\\2", names(FFdf), perl = TRUE)
cat("Dataset:", nrow(FFdf), "rows,", ncol(FFdf), "columns\n")
cat("Unique Cust_ID:", length(unique(FFdf$Cust_ID)), "out of", nrow(FFdf), "rows\n")
# Identify character variables
chr_vars <- names(FFdf)[sapply(FFdf, is.character)]
cat("Character variables to convert:", length(chr_vars), "\n")
# Convert character variables to factors
for(var in chr_vars) {
FFdf[[var]] <- as.factor(FFdf[[var]])
}
# Show key factor levels
cat("\nSex levels:", levels(FFdf$Sex), "\n")
cat("Marital levels:", levels(FFdf$Marital), "\n")
cat("Account_Type levels:", levels(FFdf$Account_Type), "\n")
# Check numeric variable ranges
cat("Age range:", range(FFdf$Age, na.rm = TRUE), "\n")
cat("Tenure range:", range(FFdf$Tenure, na.rm = TRUE), "\n")
cat("NumSeats range:", range(FFdf$NumSeats, na.rm = TRUE), "\n")
# Check for 999 placeholder values in DistA
cat("\nDistA values = 999:", sum(FFdf$DistA == 999, na.rm = TRUE), "\n")
# Convert 999 to NA (placeholder for missing)
FFdf$DistA[FFdf$DistA == 999] <- NA
cat("DistA NA count after conversion:", sum(is.na(FFdf$DistA)), "\n")
# Check Survey_Comp for outliers (expected range 0-1)
cat("\nSurvey_Comp range:", range(FFdf$Survey_Comp, na.rm = TRUE), "\n")
cat("Survey_Comp values > 1:", sum(FFdf$Survey_Comp > 1, na.rm = TRUE), "\n")
# Check for redundant columns
cat("\nState_Name unique:", length(unique(FFdf$State_Name)),
"| State_Loc unique:", length(unique(FFdf$State_Loc)), "\n")
# Convert Last_Contact to datetime format
FFdf$Last_Contact <- ymd_hms(as.character(FFdf$Last_Contact))
# Extract date components
FFdf$Contact_Year <- year(FFdf$Last_Contact)
FFdf$Contact_Month <- month(FFdf$Last_Contact)
FFdf$Contact_Day <- day(FFdf$Last_Contact)
FFdf$Contact_Weekday <- wday(FFdf$Last_Contact, label = TRUE)
FFdf$Contact_Hour <- hour(FFdf$Last_Contact)
cat("Date components extracted: Contact_Year, Contact_Month, Contact_Day, Contact_Weekday, Contact_Hour\n")
cat("Contact Year range:", range(FFdf$Contact_Year, na.rm = TRUE), "\n")
cat("Contact Hour range:", range(FFdf$Contact_Hour, na.rm = TRUE), "\n")
cat("Final Dataset:", nrow(FFdf), "rows x", ncol(FFdf), "columns\n")
cat("Total Missing Values:", sum(is.na(FFdf)), "\n")
# Show columns with missing values
na_counts <- colSums(is.na(FFdf))
na_cols <- na_counts[na_counts > 0]
cat("\nColumns with missing values:\n")
print(sort(na_cols, decreasing = TRUE))
